# Report
This is the report of findings of Part 2 - US Retail Analytics

## Background
We have a data set from a US Retail chain between 2010 and 2013. Our goal is to predict department-wide sales for each store in 2013 and 2014, find out the effectiveness of markdown on holiday weeks the US Retail offers. 

## Data Used
The data set was obtained from Kaggle. The data set consists three types of data: environment and economic indicator data of each store on a given date (Feature data), weekly sales data of each department in each store (Sales data), and meta data of each store (Store data). Feature data consists environment data, such as temperature, economic indicators, such as fuel price and consumer price index, and promotion expense offered by each store on a given week. Sales data consists of the weekly sales for each department in each store. Store data consists the meta data of each store, such as size of the store. Each data set has a Store ID that can merge together base on this key, while Store ID and Date are the keys to merge feature and sales data.

## Strategy
There are two main tasks of this part of project: Building prediction model (Task 1)and interpret markdown effects on sales (Task 2). Before working on both tasks, we made an exploratory data analysis on the data set. 
<br><br>
We have found that the aggregated sales stay flat, except the holiday season in November and December. However, the proportion of sales in holiday season is only accounted for a small proportion of annual sales; the non-holiday weeks have a larger share overall. Also, we have found that the economic indicator is relatively flat, except the fuel price has a steady rise across 2 years. 
<br><br>
After having an idea of how does the data looks like, the next step is to build a prediction model to complete Task 1. In order to build a prediction model, we have conducted model training with 4 phases using feature and sales data. Lastly, we will use filter the holiday sales from the combined feature and sales data set to fit a linear regression model to interpret the effects on Markdowns.

## Building Prediction Model for Department-wide sales for each Store in 2013 and 2014
There are two major step to complete Task 1, building prediction model for department-wide sales for each Store in 2013 and 2014: Model Training and Prototype Model Buildiing. In model training, there are 4 phases: Decide out whether build a model based on store sales or individual department sales in each store (Finding Perspective), find out which algorithm to use for prediction model (Comparing Algorithms), decide features (Exploring Features), and tune the prototype prediction model (Model Tuning). After these 4 phases have conducted, the final step is to build a final version of prediction model.
<br><br>
In the Finding Perspective phase, we have found out building models based on store sales is more effective than building models individual department sales in each store. In this approach, we would partition data based on 45 stores first. Then, we trained a sales prediction model on each store with its own sales records so that each store has its own sales prediction model. Once we have predicted the future sales for each store, we wouldl split the sales to each department in each store based on the sales proportion of each department in each store. The alternative way is building models individual department sales in each store. Similar to the first approach, the alternative approach build a prediction model for each department in each store while each prediction model directly predict future sales for each department in each store to achieve my goal. However, the performance of the alternative approach is poor as the first approach was selected in this phase.
<br><br>
The next step was Comparing Algorithms phase. In this phase, we were going to select the algorithm for building prediction model. Since the data set consists continuous data, linear regression is the algorithm to train the baseline model. We have selected 5 alternative algorithms to compare with the baseline model: support vector regressor (SVR), decision tree regressor, random forest regressor, adaptive boosting regressor, adaptive boosting regressor, and gradient boosting regressor. R-square is selected to evaluate the models. After building models with those algorithms with 10 folds, we have found the model trained with decision tree regressor achieved the highest accuracy, 92% R-square. Therefore, decision tree regressor was selected for the algorithm.
<br><br>
In the Exploring Features phases, we were trying to determine whether we shall include the Markdowns and Date as part of the features in the prediction model. In this phase, we have built models that included or excluded markdowns and date. As the result, we have found out that including markdowns and date did not help improving accuracy. Therefore, we have decided to drop both features. After we have conducting the Model Tuning, we decided to tune the model with 3 maximium depth for the decision tree regressor model. After that, we built a prototype prediction model based on the result of the model training step.
<br><br>
In the final prediciton model, we have built another prediction model to predict features data along with the prototype prediciotn model. Most of the features we used is time-series data and we need a prediction model to predict the value of those feature in 2013 and 2014 to supply the necessary information for the sales prediction model. As the result, the final prediction model is able to make prediction not even 2013 and 2014, but also beyond 2014. 
<br><br>
There are some drawbacks on the prediction model. First, the sales predicted from the model does not vary too much across. There are reasons to explain this. Firstly, the prediction model is highly trained with training data as we can see that the R-square is 92% in the comparing algorithms phase. Secondly, we use maximium depth for the decision tree regressor model is 3 that there are very limited numbers of output available. Thirdly, there are lack of unique KPIs. We can see that the KPIs available in the feature data set are related to macroeconomics indicators that there are lack of unique KPIs related to the individual stores or departments. As we have seen the indicators were relatively flat that there are lack of variation relative to weekly sales of each store. Forthly, the available of data is still small. The data set available only consist data between 2010 and 2012 that there are very limited observation for the prediction models for each store. 

## Find the Effects on Markdowns on Holiday Weeks
The only phase of Task 2, find the effects on markdowns on holiday weeks, is fit the data into a linear regression model and interpret the effects on markdowns. The first step is to filter the combined feature and sales data to holiday weeks only, then we have used this data set to fit the model and produce a summary of this linear regression model. Since this task is to interpret the effectiveness on features, we have chose linear regression as the algorithm for training the model because interpretation using linear regression is very easy to explain and understand. As the result we have found that all markdown has a positive coefficients, it means on average all promotion has a positive effectiveness to holiday sales.
<br><br>
We have found that the ranks of effectiveness, on average, were Markdown 5, Markdown 4, Markdown 3, Markdown 1, Markdown 2. Although Markdown 5 and Markdown 4 on average has the highest effectiveness on sales, the 95% confidence interval range from negative to positive values. It means we do not have 95% confidence that the effectiveness is positive on those promotion due to the high standard error to those coefficients. Surprisingly, the standard error of Markdown 3 is small that results a narrow range of 95% confidence interval in the positive area while the coefficient is relatively high. Therefore, we can see that Markdown 3 is a very reliable promotion that we can expect the sales increase at most of time if more resource is allocated to Markdown 3. Markdown 5 and Markdown 4 may be effective on sales, however, there is good chance the implement of Markdown 5 and Markdown 4 may result in decrease in sales. Therefore, we recommend this US Retail chain to allocate more resource on Markdown 3 than other promotion during holiday seasons to boost sales, instead of only allocating in Markdown 4 and Markdown 5. 

## Conclusion
We have built a prediction model to predict department-wide weekly sales and found the effects on markdowns on holiday weeks. The prediction we have built may be overtrained with training data that it may not achieve great accuracy on future sales prediction. However, we have gathered reasons why the model is not great for prediction that we can improve the prediction by go back to the model training phase and evaluate the models with different perspective, such as using other metrics and focus less on R-square. We have also interpreted the effectiveness of markdown promotion on holiday weeks and given recommendation on how to allocate resource on promotion to boost sales in holiday seasons. However, one of the difficulties we were facing in completing both tasks is that there are lack of KPI unique to the stores and departments sales that it was very hard to figure out the effects of each features. Another step could be done to improve the prediction model is to create more KPI and collect the data to include as features to help the performance of the prediction model and the intepretation.